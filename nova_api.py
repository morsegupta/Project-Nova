import os
import json
import gc
import joblib
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import traceback
from datetime import datetime

torch.set_num_threads(1)  
gc.collect()  

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class NovaScoreNN(nn.Module):
    def __init__(self, input_size, hidden_sizes=[128, 64, 32], num_classes=3):
        super(NovaScoreNN, self).__init__()
        layers = []
        prev_size = input_size
        
        for hidden_size in hidden_sizes:
            layers.extend([
                nn.Linear(prev_size, hidden_size),
                nn.BatchNorm1d(hidden_size),
                nn.ReLU(),
                nn.Dropout(0.3)
            ])
            prev_size = hidden_size
            
        self.shared_layers = nn.Sequential(*layers)
        
        self.regression_head = nn.Sequential(
            nn.Linear(prev_size, 32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, 1)
        )
        
        self.classification_head = nn.Sequential(
            nn.Linear(prev_size, 32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, num_classes)
        )
    
    def forward(self, x):
        shared_output = self.shared_layers(x)
        regression_output = self.regression_head(shared_output)
        classification_output = self.classification_head(shared_output)
        return regression_output, classification_output

class NovaScoreAPI:
    def __init__(self, model_path='models'):
        self.model_path = model_path
        self.load_models()

    def load_models(self):
        try:
            logger.info("Loading NovaScore models...")
            
            model_files = {
                'xgb_regression_26features.pkl': 'xgb_model',
                'lgb_regression_26features.pkl': 'lgb_model', 
                'scaler_26features.pkl': 'scaler',
                'label_encoder.pkl': 'label_encoder'
            }
            
            possible_paths = [
                self.model_path,  
                '.',              
                os.path.join('.', 'models'),  
            ]
            
            models_loaded = False
            
            for base_path in possible_paths:
                try:
                    logger.info(f"Trying to load models from: {base_path}")
                    
                    all_files_exist = all(
                        os.path.exists(os.path.join(base_path, filename)) 
                        for filename in model_files.keys()
                    )
                    
                    if all_files_exist:
                        logger.info("üéØ Loading unified 26-feature models...")
                        for filename, attr_name in model_files.items():
                            filepath = os.path.join(base_path, filename)
                            setattr(self, attr_name, joblib.load(filepath))
                            logger.info(f"‚úÖ Loaded {filename}")
                        
                        feature_names_loaded = False
                        for feature_file in ['feature_names_26.pkl', 'feature_names.pkl']:
                            feature_names_path = os.path.join(base_path, feature_file)
                            if os.path.exists(feature_names_path):
                                with open(feature_names_path, 'rb') as f:
                                    self.feature_names = joblib.load(f)
                                logger.info(f"‚úÖ Loaded unified feature names from {feature_file}")
                                feature_names_loaded = True
                                break
                        
                        if not feature_names_loaded:
                            self.feature_names = [
                                'trip_completion_rate', 'avg_customer_rating', 'consistency_score', 
                                'cancellation_rate', 'recent_rating_trend', 'monthly_earnings_usd', 
                                'earning_volatility', 'total_trips', 'last_30_days_trips', 
                                'recent_earnings_trend', 'tenure_months', 'feature_adoption_score', 
                                'platform_activity_days_per_month', 'grabpay_usage_frequency', 
                                'peak_hours_utilization', 'weekend_activity_ratio', 'referral_count',
                                'performance_trust', 'financial_behavior', 'platform_engagement',
                                'completion_excellence', 'rating_excellence', 'reliability_score',
                                'earnings_stability', 'trip_efficiency', 'digital_adoption'
                            ]
                            logger.info("‚úÖ Using hardcoded 26 feature names as fallback")
                        
                        models_loaded = True
                        break
                        
                except Exception as e:
                    logger.warning(f"Failed to load from {base_path}: {str(e)}")
                    continue
            
            if not models_loaded:
                logger.error("‚ùå Could not load unified 26-feature models")
                raise FileNotFoundError("Unified 26-feature models not found. Please run retrain_unified_models.py first.")
            
            try:
                metadata_path = os.path.join(base_path, 'model_metadata_26features.json')
                with open(metadata_path, 'r') as f:
                    self.metadata = json.load(f)
                logger.info("‚úÖ Loaded model metadata")
            except FileNotFoundError:
                logger.warning("model_metadata_26features.json not found, using fallback metadata")
                self.metadata = {
                    'feature_names': self.feature_names,
                    'ensemble_weights': {'xgb': 0.4, 'lgb': 0.4, 'nn': 0.2},
                    'model_performance': {'r2_score': 0.936, 'rmse': 15.76}
                }
            
            try:
                nn_path_26 = os.path.join(base_path, 'novascore_nn_26features.pth')
                logger.info(f"üîç Checking for 26-feature NN at: {nn_path_26}")
                logger.info(f"üîç File exists: {os.path.exists(nn_path_26)}")
                
                if os.path.exists(nn_path_26):
                    logger.info("üìÅ Found novascore_nn_26features.pth, attempting to load...")
                    checkpoint = torch.load(nn_path_26, map_location='cpu')
                    logger.info(f"üìã Checkpoint keys: {list(checkpoint.keys())}")
                    logger.info(f"üß† Loading 26-feature NN: input_size={checkpoint.get('input_size', 'NOT_FOUND')}")
                    
                    self.nn_model = NovaScoreNN(
                        input_size=checkpoint.get('input_size', 26),
                        num_classes=checkpoint.get('num_classes', 3)
                    )
                    self.nn_model.load_state_dict(checkpoint['model_state_dict'])
                    self.nn_model.eval()
                    logger.info("‚úÖ Successfully loaded 26-feature PyTorch Neural Network")
                    
                    dummy_input = torch.randn(1, 26)
                    with torch.no_grad():
                        test_output = self.nn_model(dummy_input)
                        logger.info(f"üß™ NN test successful: {test_output[0].item():.1f}")
                        
                    self.using_real_nn = True
                    
                else:
                    logger.warning("‚ùå 26-feature NN not found, creating mock NN for 26 features")
                    self.using_real_nn = False
                    raise FileNotFoundError("26-feature NN not available")

            except Exception as e:
                logger.warning(f"‚ùå Failed to load 26-feature PyTorch model: {str(e)}")
                logger.warning(f"üîß Error details: {traceback.format_exc()}")
                logger.info("üîÑ Creating mock NN model for 26 features...")
                self.using_real_nn = False
                self.create_mock_nn_model()
            
            logger.info("üéâ Using unified 26-feature models - single preprocessing path!")
            logger.info("‚úÖ All models loaded successfully!")

        except Exception as e:
            logger.error(f"‚ùå Error loading models: {str(e)}")
            raise

    def create_mock_nn_model(self):
        try:
            class MockNN26Features:
                def __init__(self):
                    self.feature_map = {
                        'trip_completion_rate': 0,
                        'avg_customer_rating': 1,
                        'consistency_score': 2,
                        'cancellation_rate': 3,
                        'recent_rating_trend': 4,
                        'monthly_earnings_usd': 5,
                        'earning_volatility': 6,
                        'total_trips': 7,
                        'last_30_days_trips': 8,
                        'recent_earnings_trend': 9,
                        'tenure_months': 10,
                        'feature_adoption_score': 11,
                        'platform_activity_days_per_month': 12,
                        'grabpay_usage_frequency': 13,
                        'peak_hours_utilization': 14,
                        'weekend_activity_ratio': 15,
                        'referral_count': 16,
                        'performance_trust': 17,
                        'financial_behavior': 18,
                        'platform_engagement': 19,
                        'completion_excellence': 20,
                        'rating_excellence': 21,
                        'reliability_score': 22,
                        'earnings_stability': 23,
                        'trip_efficiency': 24,
                        'digital_adoption': 25
                    }
                
                def __call__(self, x):
                    features = x.numpy() if hasattr(x, 'numpy') else x
                    
                    if features.shape[1] != 26:
                        logger.error(f"Mock NN expects 26 features, got {features.shape[1]}")
                        return (torch.tensor([[500.0]]), None) 
                    
                    completion_rate = features[0][self.feature_map['trip_completion_rate']]
                    rating = features[0][self.feature_map['avg_customer_rating']]
                    cancellation = features[0][self.feature_map['cancellation_rate']]
                    earnings = features[0][self.feature_map['monthly_earnings_usd']]
                    consistency = features[0][self.feature_map['consistency_score']]
                    tenure = features[0][self.feature_map['tenure_months']]
                    volatility = features[0][self.feature_map['earning_volatility']]
                    total_trips = features[0][self.feature_map['total_trips']]
                    feature_adoption = features[0][self.feature_map['feature_adoption_score']]
                    activity_days = features[0][self.feature_map['platform_activity_days_per_month']]
                    grabpay_usage = features[0][self.feature_map['grabpay_usage_frequency']]
                    referrals = features[0][self.feature_map['referral_count']]
                    
                    base_score = 300  
                    
                    performance_score = (
                        completion_rate * 100 +          
                        max(0, (rating - 1) * 25) +      
                        consistency * 50 +              
                        max(0, (1 - cancellation) * 50)  
                    )
                    
                    financial_score = (
                        min(earnings / 10, 60) +          
                        max(0, (1 - volatility) * 40) + 
                        min(total_trips / 50, 20)       
                    )
                    
                    engagement_score = (
                        feature_adoption * 30 +           
                        min(activity_days, 25) +         
                        grabpay_usage * 15 +            
                        min(referrals * 2, 10)    
                    )                    
                    tenure_bonus = min(tenure * 2, 50)                    
                    total_score = base_score + (
                        performance_score * 0.45 +        
                        financial_score * 0.35 +         
                        engagement_score * 0.20        
                    ) + tenure_bonus
                    
                    final_score = max(300, min(850, total_score))
                    logger.info(f"ü§ñ Mock NN: perf={performance_score:.1f}, fin={financial_score:.1f}, eng={engagement_score:.1f}, tenure={tenure_bonus:.1f} ‚Üí {final_score:.1f}")
                    
                    return (torch.tensor([[final_score]]), None)
        
            self.nn_model = MockNN26Features()
            logger.info(f"‚úÖ Created realistic mock NN model for 26 features")
        
        except Exception as e:
            logger.error(f"Failed to create mock NN model: {str(e)}")
            self.nn_model = None

    def preprocess_features(self, partner_data):
        try:
            df = pd.DataFrame([partner_data])
            
            numeric_cols = ['tenure_months', 'trip_completion_rate', 'avg_customer_rating', 
                           'consistency_score', 'cancellation_rate', 'total_trips', 
                           'monthly_earnings_usd', 'earning_volatility', 'peak_hours_utilization',
                           'weekend_activity_ratio', 'feature_adoption_score', 
                           'platform_activity_days_per_month', 'grabpay_usage_frequency',
                           'referral_count', 'last_30_days_trips', 'recent_rating_trend',
                           'recent_earnings_trend']
            
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                    if df[col].isnull().sum() > 0:
                        df[col] = df[col].fillna(0)
        
            df = self.create_premium_features(df)
            
            df['completion_excellence'] = (df['trip_completion_rate'] - 0.8) / 0.2 
            df['completion_excellence'] = df['completion_excellence'].clip(0, 1)
            
            df['rating_excellence'] = (df['avg_customer_rating'] - 3.0) / 2.0  
            df['rating_excellence'] = df['rating_excellence'].clip(0, 1)
            
            df['reliability_score'] = df['consistency_score']
            df['cancellation_penalty'] = 1 - df['cancellation_rate']
            df['recent_performance_trend'] = df['recent_rating_trend'].fillna(0)
            
            df['performance_trust'] = (
                df['completion_excellence'] ** 1.5 * 25 +      
                df['rating_excellence'] ** 1.3 * 25 +        
                df['reliability_score'] ** 1.2 * 20 +          
                df['cancellation_penalty'] ** 1.1 * 20 +   
                df['recent_performance_trend'] * 10
            ) * df['excellence_multiplier']
            
            df['earnings_normalized'] = np.log1p(df['monthly_earnings_usd']) * 10 
            df['earnings_stability'] = 1 - (df['earning_volatility'] / df['monthly_earnings_usd'].clip(lower=1))
            df['earnings_stability'] = df['earnings_stability'].clip(0, 1)
            
            df['trip_efficiency'] = df['total_trips'] / df['tenure_months'].clip(lower=1)
            df['recent_activity'] = df['last_30_days_trips'] / 30  
            df['earnings_growth_trend'] = df['recent_earnings_trend'].fillna(0)
            
            df['financial_behavior'] = (
                np.log1p(df['monthly_earnings_usd']) / 10 * 0.45 +  
                (1 - df['earning_volatility']) ** 1.5 * 0.25 +     
                np.log1p(df['total_trips']) / 15 * 0.15 +         
                np.log1p(df['last_30_days_trips']) / 8 * 0.15     
            ) * df['premium_earnings_tier'] * 0.1 + (          
                df['earnings_normalized'] * 30 +
                df['earnings_stability'] * 25 +
                df['trip_efficiency'] * 20 +
                df['recent_activity'] * 15 +
                df['earnings_growth_trend'] * 10
            ) * df['excellence_multiplier']
            
            df['digital_adoption'] = df['feature_adoption_score'] * 20
            df['platform_consistency'] = df['platform_activity_days_per_month'] / 30 * 20
            df['payment_integration'] = df['grabpay_usage_frequency'] * 5
            df['peak_engagement'] = df['peak_hours_utilization'] * 15
            df['weekend_availability'] = df['weekend_activity_ratio'] * 10
            df['community_impact'] = df['referral_count'] * 2
            df['tenure_loyalty'] = np.log1p(df['tenure_months']) * 5
            
            df['platform_engagement'] = (
                df['feature_adoption_score'] ** 1.2 * 0.30 +       
                (df['platform_activity_days_per_month'] / 30) ** 1.1 * 0.25 + 
                df['grabpay_usage_frequency'] ** 1.3 * 0.20 +    
                np.log1p(df['referral_count']) / 5 * 0.15 +      
                df['peak_hours_utilization'] * 0.10               
            ) * df['digital_leadership'] * 0.1 + (          
                df['digital_adoption'] * 25 +
                df['platform_consistency'] * 20 +
                df['payment_integration'] * 15 +
                df['peak_engagement'] * 15 +
                df['weekend_availability'] * 10 +
                df['community_impact'] * 10 +
                df['tenure_loyalty'] * 5
            ) * df['excellence_multiplier']
            
            feature_names_26 = [
                'trip_completion_rate', 'avg_customer_rating', 'consistency_score', 
                'cancellation_rate', 'recent_rating_trend', 'monthly_earnings_usd', 
                'earning_volatility', 'total_trips', 'last_30_days_trips', 
                'recent_earnings_trend', 'tenure_months', 'feature_adoption_score', 
                'platform_activity_days_per_month', 'grabpay_usage_frequency', 
                'peak_hours_utilization', 'weekend_activity_ratio', 'referral_count',
                
                'performance_trust', 'financial_behavior', 'platform_engagement',
                'completion_excellence', 'rating_excellence', 'reliability_score',
                'earnings_stability', 'trip_efficiency', 'digital_adoption'
            ]
            
            for col in feature_names_26:
                if col not in df.columns:
                    df[col] = 0
            
            features = df[feature_names_26].fillna(0)
            logger.info(f"üéØ Enhanced preprocessing: {features.shape} features with premium detection")
            
            return features
                
        except Exception as e:
            logger.error(f"Error in preprocessing: {str(e)}")
            raise

    def create_premium_features(self, df):
        """Create features that better identify premium-tier partners"""
        
        df['excellence_multiplier'] = 1.0
        
        exceptional_performance = (
            (df['trip_completion_rate'] >= 0.95) & 
            (df['avg_customer_rating'] >= 4.7) & 
            (df['consistency_score'] >= 0.85)
        )
        df.loc[exceptional_performance, 'excellence_multiplier'] *= 1.25
        
        df['premium_earnings_tier'] = 0
        df.loc[df['monthly_earnings_usd'] >= 800, 'premium_earnings_tier'] = 1
        df.loc[df['monthly_earnings_usd'] >= 1200, 'premium_earnings_tier'] = 2
        df.loc[df['monthly_earnings_usd'] >= 1600, 'premium_earnings_tier'] = 3
        
        df['digital_leadership'] = (
            df['feature_adoption_score'] * 0.4 +
            df['grabpay_usage_frequency'] * 0.3 +
            (df['platform_activity_days_per_month'] / 30) * 0.3
        ) * df['excellence_multiplier']
        
        df['experience_quality'] = (
            np.log1p(df['tenure_months']) * 0.3 +
            np.log1p(df['total_trips']) * 0.2 +
            df['trip_completion_rate'] * 0.25 +
            (df['avg_customer_rating'] / 5.0) * 0.25
        ) * df['excellence_multiplier']
        
        df['market_leadership'] = (
            np.log1p(df['referral_count']) * 0.4 +
            np.clip(df['recent_rating_trend'], 0, 0.5) * 0.3 +
            np.clip(df['recent_earnings_trend'], 0, 0.3) * 0.3
        ) * df['excellence_multiplier']
        
        logger.info(f"üéØ Premium feature engineering applied: excellence_multiplier range {df['excellence_multiplier'].min():.2f}-{df['excellence_multiplier'].max():.2f}")
        
        return df

    def predict(self, partner_data):
        try:
            features = self.preprocess_features(partner_data)
            
            scaled_features = self.scaler.transform(features)
            
            xgb_pred = float(self.xgb_model.predict(scaled_features)[0])
            lgb_pred = float(self.lgb_model.predict(scaled_features)[0])
            
            try:
                if self.nn_model is not None:
                    tensor_input = torch.tensor(scaled_features, dtype=torch.float32)
                    with torch.no_grad():
                        nn_output = self.nn_model(tensor_input)
                        if isinstance(nn_output, tuple):
                            nn_pred_raw = float(nn_output[0][0].item())
                        else:
                            nn_pred_raw = float(nn_output[0].item())

                    tree_avg = (xgb_pred + lgb_pred) / 2
                    
                    deviation = abs(nn_pred_raw - tree_avg)
                    if deviation > 50:
                        tree_weight = min(0.7, deviation / 150)  
                        nn_weight = 1 - tree_weight
                        
                        nn_pred = (nn_pred_raw * nn_weight) + (tree_avg * tree_weight)
                        logger.info(f"üîß NN calibration applied: deviation={deviation:.1f}, tree_weight={tree_weight:.2f}")
                    else:
                        nn_pred = nn_pred_raw
                        logger.info(f"‚úÖ NN prediction accepted: deviation={deviation:.1f} within tolerance")
                    
                    nn_pred = max(300, min(850, nn_pred))
                    
                    nn_type = "REAL" if getattr(self, 'using_real_nn', False) else "MOCK"
                    logger.info(f"üß† {nn_type} NN: raw={nn_pred_raw:.1f}, final={nn_pred:.1f}, tree_avg={tree_avg:.1f}")
                else:
                    nn_pred = (xgb_pred + lgb_pred) / 2
                    logger.warning("Using fallback NN prediction")
            except Exception as e:
                logger.error(f"NN prediction failed: {str(e)}, using fallback")
                nn_pred = (xgb_pred + lgb_pred) / 2
            
            logger.info(f"üéØ Model predictions: XGB={xgb_pred:.1f}, LGB={lgb_pred:.1f}, NN={nn_pred:.1f}")
            
            xgb_pred = max(300, min(850, xgb_pred))
            lgb_pred = max(300, min(850, lgb_pred))
            nn_pred = max(300, min(850, nn_pred))
            
            predictions = {
                'xgb': float(xgb_pred),
                'lgb': float(lgb_pred),
                'nn': float(nn_pred)
            }
            
            weights = self.metadata.get('ensemble_weights', {'xgb': 0.4, 'lgb': 0.4, 'nn': 0.2})
            
            ensemble_score = (
                predictions['xgb'] * weights['xgb'] +
                predictions['lgb'] * weights['lgb'] +
                predictions['nn'] * weights['nn']
            )
            
            ensemble_score = max(300, min(850, ensemble_score))
            
            final_score = self.calibrate_premium_scores(ensemble_score, partner_data)
            final_score = max(300, min(850, final_score))
            
            logger.info(f"üèÜ Final calibrated score: {final_score:.1f} (raw ensemble: {ensemble_score:.1f})")
            
            risk_category = self._determine_risk_category(final_score)
            loan_eligibility = self._determine_loan_eligibility(final_score)
            
            result = {
                'nova_score': round(final_score),
                'risk_category': risk_category,
                'loan_eligibility': loan_eligibility,
                'model_predictions': predictions,
                'ensemble_weights': weights,
                'unified_models': True,
                'feature_count': len(self.feature_names),
                'raw_ensemble_score': round(ensemble_score),
                'calibration_applied': final_score != ensemble_score
            }
            
            logger.info(f"Final prediction: {result}")
            return result
            
        except Exception as e:
            logger.error(f"Prediction failed: {str(e)}")
            logger.error(traceback.format_exc())
            raise

    def calibrate_premium_scores(self, raw_score, partner_data):
        is_premium_candidate = (
            partner_data.get('trip_completion_rate', 0) >= 0.95 and
            partner_data.get('avg_customer_rating', 0) >= 4.7 and
            partner_data.get('monthly_earnings_usd', 0) >= 1000 and
            partner_data.get('consistency_score', 0) >= 0.85 and
            partner_data.get('feature_adoption_score', 0) >= 0.8
        )
        
        is_poor_performer = (
            partner_data.get('trip_completion_rate', 1) <= 0.75 and
            partner_data.get('avg_customer_rating', 5) <= 3.5 and
            partner_data.get('monthly_earnings_usd', 1000) <= 300 and
            partner_data.get('consistency_score', 1) <= 0.45 and
            partner_data.get('cancellation_rate', 0) >= 0.2
        )
        
        excellence_factors = [
            min(partner_data.get('trip_completion_rate', 0) / 0.99, 1.0), 
            min(partner_data.get('avg_customer_rating', 0) / 5.0, 1.0),   
            min(partner_data.get('monthly_earnings_usd', 0) / 2000, 1.0), 
            min(partner_data.get('consistency_score', 0) / 1.0, 1.0),  
            min(partner_data.get('feature_adoption_score', 0) / 1.0, 1.0), 
            min(partner_data.get('tenure_months', 0) / 36, 1.0),         
            min((1 - partner_data.get('earning_volatility', 1)) / 1.0, 1.0), 
            min((1 - partner_data.get('cancellation_rate', 1)) / 1.0, 1.0)  
        ]
        
        excellence_score = sum(excellence_factors) / len(excellence_factors)
        
        logger.info(f"üéØ Score calibration: excellence_score={excellence_score:.3f}, is_premium={is_premium_candidate}, is_poor={is_poor_performer}, raw_score={raw_score:.1f}")
        
        if is_premium_candidate and excellence_score >= 0.85:
            if raw_score >= 600:
                score_above_600 = raw_score - 600
                premium_boost = score_above_600 * (1 + excellence_score * 0.8)
                calibrated_score = 600 + premium_boost
                
                if excellence_score >= 0.95:
                    calibrated_score += 25  
                elif excellence_score >= 0.90:
                    calibrated_score += 15
                
                logger.info(f"üèÜ Premium boost applied: {raw_score:.1f} ‚Üí {calibrated_score:.1f} (excellence: {excellence_score:.3f})")
                return min(calibrated_score, 850)  
        
        elif is_poor_performer and excellence_score <= 0.35:
            if raw_score >= 400:  
                poor_penalty = (raw_score - 400) * (0.5 - excellence_score) 
                calibrated_score = 400 - poor_penalty
                
                performance_penalties = 0
                
                if partner_data.get('trip_completion_rate', 1) <= 0.70:
                    performance_penalties += 20
                    
                if partner_data.get('avg_customer_rating', 5) <= 3.0:
                    performance_penalties += 15
                    
                if partner_data.get('cancellation_rate', 0) >= 0.25:
                    performance_penalties += 15
                    
                if partner_data.get('monthly_earnings_usd', 1000) <= 250:
                    performance_penalties += 20
                    
                if partner_data.get('earning_volatility', 0) >= 0.6:
                    performance_penalties += 10
                    
                if partner_data.get('recent_rating_trend', 0) <= -0.1:
                    performance_penalties += 10
                if partner_data.get('recent_earnings_trend', 0) <= -0.1:
                    performance_penalties += 10
                
                calibrated_score -= performance_penalties
                calibrated_score = max(calibrated_score, 300)
                
                logger.info(f"üö® Poor performer penalty applied: {raw_score:.1f} ‚Üí {calibrated_score:.1f} (excellence: {excellence_score:.3f}, penalties: {performance_penalties})")
                return calibrated_score
        
        elif excellence_score >= 0.75:
            if raw_score >= 550:
                moderate_boost = (raw_score - 550) * (1 + excellence_score * 0.3)
                calibrated_score = 550 + moderate_boost
                logger.info(f"üìà Moderate boost applied: {raw_score:.1f} ‚Üí {calibrated_score:.1f}")
                return min(calibrated_score, 750) 
        
        elif excellence_score <= 0.50 and raw_score >= 450:
            downward_adjustment = (raw_score - 450) * (0.6 - excellence_score) * 0.3
            calibrated_score = raw_score - downward_adjustment
            logger.info(f"üìâ Below-average adjustment: {raw_score:.1f} ‚Üí {calibrated_score:.1f} (excellence: {excellence_score:.3f})")
            return max(calibrated_score, 350)
        
        return raw_score

    def _determine_risk_category(self, score):
        if score >= 650:
            return "Low"
        elif score >= 500:
            return "Medium"
        else:
            return "High"

    def _determine_loan_eligibility(self, score):
        if score >= 700:
            return {
                "eligible": True,
                "max_loan_amount": 50000,
                "interest_rate": 5.5,
                "loan_term_months": 60,
                "confidence": "High"
            }
        elif score >= 600:
            return {
                "eligible": True,
                "max_loan_amount": 25000,
                "interest_rate": 8.5,
                "loan_term_months": 48,
                "confidence": "Medium"
            }
        elif score >= 500:
            return {
                "eligible": True,
                "max_loan_amount": 10000,
                "interest_rate": 12.0,
                "loan_term_months": 36,
                "confidence": "Low"
            }
        else:
            return {
                "eligible": True,
                "max_loan_amount": 2000,
                "interest_rate": 18.0,
                "loan_term_months": 12,
                "confidence": "Emergency Only",
                "reason": "Emergency loan only"
            }

app = Flask(__name__)
CORS(app)

try:
    nova_api = NovaScoreAPI()
    logger.info("üöÄ NovaScore API initialized successfully!")
except Exception as e:
    logger.error(f"Failed to initialize NovaScore API: {e}")
    nova_api = None

@app.route('/')
def index():
    return jsonify({'message': 'NovaScore API is running!'})

@app.route('/api/predict', methods=['POST'])
def predict():
    try:
        if not nova_api:
            return jsonify({'error': 'Models not loaded'}), 500

        data = request.get_json()
        if not data:
            return jsonify({'error': 'No data provided'}), 400

        result = nova_api.predict(data)
        return jsonify({'success': True, 'prediction': result})

    except Exception as e:
        logger.error(f"Prediction endpoint error: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy',
        'models_loaded': nova_api is not None,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/api/model_info', methods=['GET'])
def model_info():
    if not nova_api:
        return jsonify({'error': 'Models not loaded'}), 500

    return jsonify({
        'features_required': nova_api.metadata.get('feature_columns', []),
        'performance_metrics': nova_api.metadata.get('model_performance', {}),
        'last_updated': datetime.now().isoformat()
    })

if __name__ == '__main__':
    print("üöÄ Starting NovaScore Production API...")
    print("üåê Health Check: http://localhost:5001/api/health")
    print("üìã API Endpoints:")
    print("  POST /api/predict - Make predictions")
    print("  GET /api/health - Health check")  
    print("  GET /api/model_info - Model information")
    
    app.run(debug=True, threaded=False, host='0.0.0.0', port=5001)
